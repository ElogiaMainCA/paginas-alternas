# üîé Auditor√≠a de Etiquetas Can√≥nicas en P√°ginas Alternas (Home, Landings, etc.) y Gesti√≥n v√≠a robots.txt

## üéØ Objetivo

Garantizar que todas las p√°ginas clave del sitio (**Home**, **Landings**, **PLPs**, **PDPs**) utilicen correctamente una sola etiqueta can√≥nica v√°lida y que **las versiones alternas o duplicadas sean bloqueadas** desde el archivo `robots.txt` para optimizar la indexaci√≥n.

---

## üß© Descripci√≥n del Problema

Durante la auditor√≠a t√©cnica de **https://www.cyamoda.com**, se identific√≥ que:

- Algunas p√°ginas (como landings o variaciones con par√°metros UTM, `?cid=`, `?utm_source=`, etc.) **no declaran una etiqueta can√≥nica correcta** o **carecen de ella**.
- Existen **variantes accesibles v√≠a diferentes rutas**, como:
  - `/home`
  - `/default`
  - `/landingpage?cid=...`
- Estas variantes **pueden ser indexadas por error** en Google y diluir la autoridad del contenido principal.

---

## üìå Ejemplos Detectados

| P√°gina | Estado de Canonical | Observaciones |
|--------|---------------------|---------------|
| `/` (Home) | ‚úÖ Correcta | Canonical bien configurada |
| `/home` | ‚ö†Ô∏è Incorrecta o ausente | Debe redirigir o usar misma canonical que `/` |
| `/landingpage?cid=x` | ‚ùå No canonical | Puede ser indexada por Google |
| `/mujer.html?utm_source=...` | ‚ö†Ô∏è Duplicado con canonical inconsistente | Necesita consolidaci√≥n |

---

## ‚ö†Ô∏è Impacto SEO

- **Dispersi√≥n de autoridad** entre URLs alternas.
- **Indexaci√≥n innecesaria** de URLs con par√°metros.
- **Contenido duplicado** interno.
- **Confusi√≥n de se√±ales** para los motores de b√∫squeda.
- **Reducci√≥n del crawl budget**, especialmente en sitios con alta paginaci√≥n.

---

## ‚úÖ Recomendaciones

### 1. Unificaci√≥n de Canonicals

Asegurar que cada p√°gina tenga **una sola etiqueta can√≥nica declarada en `<head>`**, y que esta:

- Apunte a la **versi√≥n limpia y amigable** de la URL.
- **No incluya par√°metros** (`cid`, `utm_`, `gclid`, etc.).
- Sea generada **por el backend** (SFCC/Demandware), no por scripts.

**Ejemplo correcto para Home:**

html
<link rel="canonical" href="https://www.cyamoda.com/" />



-------------


2. Revisi√≥n de Canonicals en Plantillas de Landings
Revisar templates .isml utilizados para landings y banners temporales.
Asegurar que el canonical:
Apunte a la URL sin par√°metros.
Se genere desde el controller si es din√°mica.
3. Redirecciones 301 (Opcional)
Redirigir variantes como /home ‚Üí /
Redirigir landings caducas ‚Üí categor√≠a principal o /
üîí Gesti√≥n con Robots.txt

Objetivo:
Evitar que variantes de URLs no can√≥nicas sean rastreadas por Google.

Propuesta de l√≠neas en robots.txt:
# Bloqueo de URLs con par√°metros innecesarios
Disallow: /*?cid=
Disallow: /*?utm_
Disallow: /*?gclid
Disallow: /*?fbclid
Disallow: /home
Disallow: /default
Disallow: /landingpage
Notas:

Se puede utilizar el Disallow: /*? para bloquear todos los par√°metros si es seguro hacerlo.
Es importante mantener en producci√≥n un robots.txt bien probado para no bloquear rutas necesarias.
üß™ Verificaci√≥n T√©cnica

Herramientas sugeridas:
Google Search Console ‚Üí Inspecci√≥n de URLs indexadas
Screaming Frog SEO Spider (modo JS render) ‚Üí Identificaci√≥n de canonicals
Ahrefs / SEMrush ‚Üí Auditor√≠a de contenido duplicado y canonicals
DevTools + JavaScript habilitado ‚Üí Validar DOM final (document.querySelectorAll('link[rel="canonical"]'))
Comandos de Google para verificaci√≥n:
site:cyamoda.com inurl:cid=
site:cyamoda.com inurl:utm_
site:cyamoda.com inurl:landingpage
üìÖ Plan de Acci√≥n Recomendado

Fase	Descripci√≥n	Duraci√≥n estimada
Mapeo de URLs duplicadas	Usar GSC + Ahrefs para detectar p√°ginas alternas indexadas	1 d√≠a
Auditor√≠a de canonicals	Validar configuraci√≥n de etiquetas en Home, PLP, PDP, Landings	2 d√≠as
Configuraci√≥n de robots.txt	Incluir reglas y validarlas con robots.txt tester	1 d√≠a
QA + Redirecciones	Verificar variantes activas y si es mejor redirigir	1-2 d√≠as
Implementaci√≥n	Push a producci√≥n	1 d√≠a
Monitoreo post-lanzamiento	Validar cambios en indexaci√≥n y cobertura de GSC	7 d√≠as
üß† Conclusi√≥n

Establecer una estrategia clara para canonicals en p√°ginas alternas y complementar con reglas en robots.txt es esencial para:

Consolidar autoridad.
Mejorar el posicionamiento de URLs prioritarias.
Evitar duplicidad de contenido.
Optimizar la eficiencia del rastreo (crawl budget).
Recomendamos realizar este ajuste antes del siguiente cambio de temporada o campa√±a de alto tr√°fico.
